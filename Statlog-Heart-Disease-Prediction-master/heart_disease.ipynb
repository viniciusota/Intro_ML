{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sporting-lotus",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy  as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler,StandardScaler,MinMaxScaler , PowerTransformer \n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-wealth",
   "metadata": {},
   "source": [
    "## import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "broken-narrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv( 'heart.csv' ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-elite",
   "metadata": {},
   "source": [
    "### Change output col to 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "typical-chinese",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['output'] = data['output'] - 1 \n",
    "data['exercise'] = data['exercise']-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-sewing",
   "metadata": {},
   "source": [
    "### Selecting cols by type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "governmental-shape",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data['output']\n",
    "X = data.drop('output',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-stockholm",
   "metadata": {},
   "source": [
    "### Split in train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "involved-antenna",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split( X,Y,random_state=72,test_size=0.15 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "induced-edmonton",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = ['age','restbp','chol','maxhr','dep','fluor']\n",
    "categorical_features = [ 'chestpain','ecg','thal']\n",
    "others_features = set( X_train.columns ) - set( categorical_features ) - set( numeric_columns ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-mongolia",
   "metadata": {},
   "source": [
    "### Function to preprocessing numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "strange-defeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_standard(data_to_standard,padronizacao):\n",
    "    numeric_columns = ['age','restbp','chol','maxhr','dep','fluor']\n",
    "    \n",
    "    if padronizacao == 'Standard':\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train[numeric_columns])\n",
    "        return pd.DataFrame(scaler.transform( data_to_standard[numeric_columns] ) , columns = data_to_standard[numeric_columns].columns)\n",
    "    if padronizacao == 'MinMax':\n",
    "        minmax = MinMaxScaler() \n",
    "        minmax.fit( X_train[numeric_columns] )\n",
    "        return pd.DataFrame( minmax.transform( data_to_standard[numeric_columns] ), columns = data_to_standard[numeric_columns].columns )\n",
    "\n",
    "    \n",
    "def preprocessing_categorical(data_to_standard):\n",
    "    enc = OneHotEncoder( handle_unknown='error' , sparse= False,drop='first' ).fit( X_train[categorical_features] )\n",
    "    return pd.DataFrame(enc.transform( data_to_standard[categorical_features] ) , columns = enc.get_feature_names( categorical_features ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thorough-eating",
   "metadata": {},
   "source": [
    "### Aplicando preprocessamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "brief-lexington",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([\n",
    "                 preprocessing_categorical( X_train ),\n",
    "                 X_train[others_features].reset_index().drop(\"index\",axis=1),\n",
    "                 preprocessing_standard(X_train,padronizacao='MinMax')\n",
    "                 ],axis=1\n",
    "                 )\n",
    "\n",
    "\n",
    "test = pd.concat([\n",
    "                 preprocessing_categorical( X_test ),\n",
    "                 X_test[others_features].reset_index().drop(\"index\",axis=1),\n",
    "                 preprocessing_standard(X_test,'MinMax')\n",
    "                 ],\n",
    "                 axis=1\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "progressive-postage",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "parametros_regularizacao = ['l1', 'l2', 'elasticnet','none']\n",
    "fit_log = LogisticRegression().fit(train,y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
